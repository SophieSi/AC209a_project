{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read 7-year-old data\n",
    "data_path = './ncds_sweep0-3/tab/ncds0123.tab'\n",
    "data = pd.read_csv(data_path, delimiter='\\t').set_index('ncdsid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n415: 1M Epileptic condition\n",
    "# 2: no\n",
    "# 1, -1: defect data\n",
    "# obtained at 1965, 7y\n",
    "\n",
    "# n2032: 3M Epilepsy\n",
    "# 1: no\n",
    "# -1: defect data\n",
    "# obtained at 1974, 16y\n",
    "\n",
    "# focus on those not epileptic at 1965 but epileptic at 1969"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13901 people have no epilepsy at 1965 (7-year-old)\n",
      "60 people have epilepsy at 1974 (16-year-old)\n",
      "32 people have no epilepsy at 7-year-old but have epilepsy at 16-year-old\n",
      "\n",
      "Their id number:\n",
      "['N10166J' 'N10171F' 'N10370L' 'N10597D' 'N10926A' 'N11763D' 'N11767H'\n",
      " 'N12258V' 'N13349B' 'N14147X' 'N17236K' 'N17347R' 'N17839G' 'N18241L'\n",
      " 'N18731Z' 'N19076V' 'N19158W' 'N20286W' 'N20371S' 'N20374V' 'N22184Z'\n",
      " 'N22487M' 'N22895Z' 'N23481K' 'N24216Y' 'N24233Z' 'N24494U' 'N25162F'\n",
      " 'N25418L' 'N25591Y' 'N26543U' 'N27163Q']\n"
     ]
    }
   ],
   "source": [
    "mask_1M_no = data['n415'] == '2'\n",
    "\n",
    "mask_3M_no = (data['n2032'] == '1')\n",
    "mask_3M_defect = (data['n2032'] == '-1') | (data['n2032'] == ' ') | (data['n2032'] == '2')\n",
    "mask_3M_yes = ~(mask_3M_no | mask_3M_defect)\n",
    "\n",
    "mask_1M_no_3M_yes = mask_1M_no & mask_3M_yes\n",
    "\n",
    "print '{} people have no epilepsy at 1965 (7-year-old)'.format(sum(mask_1M_no))\n",
    "print '{} people have epilepsy at 1974 (16-year-old)'.format(sum(mask_3M_yes))\n",
    "print '{} people have no epilepsy at 7-year-old but have epilepsy at 16-year-old'.format(\\\n",
    "    sum(mask_1M_no_3M_yes))\n",
    "print '\\nTheir id number:'\n",
    "print data.index[mask_1M_no_3M_yes].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predictor variables are those in 1, 2, 3 but no keyword 'epilep' in manual\n",
    "# response variable is 'acquired epilepsy', all mask_1M_no, those in mask_3M_yes are 1, else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epilepsy condition survey:\n",
      "0.0    9382\n",
      "1.0      32\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "doi = data[mask_1M_no]\n",
    "y_df = pd.Series( np.zeros(data.shape[0]) )\n",
    "y_df[mask_1M_no_3M_yes.values] = 1\n",
    "y_df = y_df[mask_1M_no.values]\n",
    "\n",
    "mask_3M_defect = (doi['n2032'] == '-1') | (doi['n2032'] == ' ') | (doi['n2032'] == '2')\n",
    "y_df = y_df[~mask_3M_defect.values]\n",
    "\n",
    "print 'Epilepsy condition survey:'\n",
    "print y_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# file path of explain file\n",
    "explain_path = '/Users/hung-yiwu/Documents/AC209a_project/data/ncds_sweep0-3/mrdoc/allissue/ncds0123_ukda_data_dictionary.rtf'\n",
    "\n",
    "# open explain file\n",
    "explain = open(explain_path, 'r')\n",
    "\n",
    "# read the whole file as a single giant string\n",
    "explain_text = explain.read()\n",
    "\n",
    "# SPSS measurement level target string\n",
    "target_string_1 = 'the SPSS measurement level is '\n",
    "\n",
    "# locate SPSS measurement level\n",
    "target_loc_1 = [m.end() for m in re.finditer(target_string_1, explain_text)]\n",
    "\n",
    "# variable label target string\n",
    "target_string_2 = 'Variable label = '\n",
    "\n",
    "# locate variable label\n",
    "target_loc_2 = [m.end() for m in re.finditer(target_string_2, explain_text)]\n",
    "\n",
    "# remove the first one (id)\n",
    "target_loc_2 = target_loc_2[1:]\n",
    "\n",
    "# variable code target string\n",
    "target_string_3 = 'Variable = '\n",
    "\n",
    "# locate variable code\n",
    "target_loc_3 = [m.end() for m in re.finditer(target_string_3, explain_text)]\n",
    "\n",
    "# remove the first one (id)\n",
    "target_loc_3 = target_loc_3[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var_df = pd.DataFrame({}, columns = ['type', 'label'])\n",
    "\n",
    "for i in range(len(target_loc_1)):\n",
    "    # get variable code\n",
    "    start_pt = target_loc_3[i]+15\n",
    "    end_pt = explain_text.find('cf1', start_pt)-6\n",
    "    var_code = explain_text[start_pt:end_pt]\n",
    "    \n",
    "    # get variable label\n",
    "    start_pt = target_loc_2[i]+7\n",
    "    end_pt = explain_text.find('\\par', start_pt)\n",
    "    var_label = explain_text[start_pt:end_pt]\n",
    "    \n",
    "    # get variable type\n",
    "    char = explain_text[target_loc_1[i] + 9] \n",
    "    if char == 'O' or char == 'o' or char == 'N' or char == 'n' \\\n",
    "        or 'region' in var_code:\n",
    "        var_type = 'categorical'\n",
    "    else:\n",
    "        var_type = 'numerical'\n",
    "\n",
    "    # append to DataFrame\n",
    "    var_df.loc[var_code] = [var_type, var_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1764 variables\n",
      "sample variable list:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n622</th>\n",
       "      <td>categorical</td>\n",
       "      <td>0-3D Sex of child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n0region</th>\n",
       "      <td>categorical</td>\n",
       "      <td>Region at PMS (1958) - Birth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n1region</th>\n",
       "      <td>categorical</td>\n",
       "      <td>Region at NCDS1 (1965) - 7 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n2region</th>\n",
       "      <td>categorical</td>\n",
       "      <td>Region at NCDS2 (1969) - 11 years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n3region</th>\n",
       "      <td>categorical</td>\n",
       "      <td>Region at NCDS3 (1974) - 16 years</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 type                              label\n",
       "n622      categorical                  0-3D Sex of child\n",
       "n0region  categorical       Region at PMS (1958) - Birth\n",
       "n1region  categorical   Region at NCDS1 (1965) - 7 years\n",
       "n2region  categorical  Region at NCDS2 (1969) - 11 years\n",
       "n3region  categorical  Region at NCDS3 (1974) - 16 years"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print '{} variables'.format(var_df.shape[0])\n",
    "print 'sample variable list:'\n",
    "var_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1764 predictors in file\n",
      "1196 predictors of interest\n"
     ]
    }
   ],
   "source": [
    "variable_of_interest = []\n",
    "for index, row in var_df.iterrows():\n",
    "    starting_text = row['label'][0:1]\n",
    "    if 'epilep' in row['label'] or 'Epilep' in row['label']:\n",
    "        continue\n",
    "    if 'convuls' in row['label'] or 'Convuls' in row['label']:\n",
    "        continue\n",
    "    if 'Special Education' in row['label']:\n",
    "        continue\n",
    "    if 'Region' in row['label']:\n",
    "        continue\n",
    "    if 'neuro' in row['label']:\n",
    "        continue\n",
    "    if 'Reason' in row['label'] or 'reason' in row['label']:\n",
    "        continue\n",
    "    if 'handicap' in row['label']:\n",
    "        continue\n",
    "    if 'psychi' in row['label']:\n",
    "        continue\n",
    "    if 'patient' in row['label']:\n",
    "        continue\n",
    "    if index == 'n1910':\n",
    "        continue\n",
    "    if index == 'n1964':\n",
    "        continue\n",
    "    if index == 'n2032':\n",
    "        continue\n",
    "    if index == 'n2416':\n",
    "        continue\n",
    "    if index == 'n2598':\n",
    "        continue\n",
    "    if index == 'n2603':\n",
    "        continue\n",
    "    if index == 'n2604':\n",
    "        continue\n",
    "    if index == 'n2605':\n",
    "        continue\n",
    "    if index == 'n2606':\n",
    "        continue\n",
    "    if index == 'n2607':\n",
    "        continue\n",
    "    if index == 'n2608':\n",
    "        continue\n",
    "    if index == 'n2663':\n",
    "        continue\n",
    "    if index == 'n2664':\n",
    "        continue\n",
    "    if index == 'n2665':\n",
    "        continue\n",
    "    if index == 'n2666':\n",
    "        continue\n",
    "    if index == 'n2667':\n",
    "        continue\n",
    "    if index == 'n622' or starting_text == '2' or starting_text == '3':\n",
    "        variable_of_interest.append(index)\n",
    "\n",
    "print '{} predictors in file'.format( var_df.shape[0] )\n",
    "print '{} predictors of interest'.format( len(variable_of_interest) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_df = doi[variable_of_interest]\n",
    "x_df = x_df[~mask_3M_defect]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9414 observations\n",
      "8724 variables (after dummy expansion)\n"
     ]
    }
   ],
   "source": [
    "# iterate through all variables\n",
    "# dummify categorical variables\n",
    "# standardize numeric variables\n",
    "\n",
    "x_df_extended_list = []\n",
    "\n",
    "for col in x_df.columns:\n",
    "    # if this column is categorical\n",
    "    if var_df.loc[col, 'type'] == 'categorical':\n",
    "        # copy current column\n",
    "        curr_df = x_df[col].copy()\n",
    "        # format all value to string\n",
    "        curr_df = curr_df.astype(str)\n",
    "        # set value ' ' to value '-1'\n",
    "        curr_df[curr_df == ' '] = '-1'\n",
    "        # if this column contains NaN\n",
    "        if curr_df.isnull().values.any():\n",
    "            # get dummy with NaN as a unique value\n",
    "            dummy = pd.get_dummies(curr_df, dummy_na = True)\n",
    "        # if this column does not contain NaN\n",
    "        else:\n",
    "            # get dummy without considering NaN\n",
    "            dummy = pd.get_dummies(curr_df, dummy_na = False)\n",
    "        # reset column label of dummy\n",
    "        dummy.columns = [str(col)+'='+str(value) for value in dummy.columns]\n",
    "        # reset index label of dummy\n",
    "        dummy.index = x_df.index\n",
    "        # append current dummy DataFrame to master list\n",
    "        x_df_extended_list.append(dummy)\n",
    "    # if this column is numerical\n",
    "    else:\n",
    "        # copy current column\n",
    "        curr_df = x_df[col].copy()\n",
    "        # set value ' ' to value -1\n",
    "        curr_df[curr_df == ' '] = -1\n",
    "        # set value NaN to value -1\n",
    "        curr_df[curr_df.isnull()] = -1\n",
    "        # convert current column to float\n",
    "        curr_df = curr_df.astype(float)\n",
    "        # standardize it\n",
    "        curr_df = pd.DataFrame(scale(curr_df.values))\n",
    "        # reset index label of current DataFrame\n",
    "        curr_df.index = x_df.index\n",
    "        # reset column name of current DataFrame\n",
    "        curr_df.columns = [col]\n",
    "        # append current DataFrame to master list\n",
    "        x_df_extended_list.append(curr_df)\n",
    "        \n",
    "# concatenate master list to get master data\n",
    "x_df_extended = pd.concat(x_df_extended_list, axis = 1)\n",
    "\n",
    "print '{} observations'.format(x_df_extended.shape[0])\n",
    "print '{} variables (after dummy expansion)'.format(x_df_extended.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "x_df_extended = pd.DataFrame(pca.fit_transform(x_df_extended.values))\n",
    "x_df_extended.columns = ['component_'+str(i) for i in 1+np.arange(x_df_extended.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scorer(estimator, x, y):\n",
    "    y_predict = estimator.predict(x)\n",
    "    cm = confusion_matrix(y, y_predict)\n",
    "    accuracy_all = estimator.score(x, y)\n",
    "    accuracy_healthy = float(cm[0,0])/float(cm[0,0]+cm[0,1])\n",
    "    accuracy_epilepsy = float(cm[1,1])/float(cm[1,0]+cm[1,1])\n",
    "    return accuracy_epilepsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight_list = [{1:value} for value in 10**np.arange(0, 3, 1)]\n",
    "penalty_list = ['l1', 'l2']\n",
    "parameters = {'class_weight':weight_list, 'penalty':penalty_list}\n",
    "gscv = GridSearchCV(LogisticRegression(C = 10**10, solver = 'liblinear'),\\\n",
    "                    parameters, scoring = 'roc_auc')\n",
    "\n",
    "#weight_list = [{1:value} for value in 10**np.arange(0, 3, 1)]\n",
    "#n_est = [5, 10, 50, 100, 500]\n",
    "#n_depth = [1, 2, 3, 4, 5]\n",
    "#parameters = {'n_estimators':n_est, 'max_depth':n_depth, 'class_weight':weight_list}\n",
    "#gscv = GridSearchCV(RandomForestClassifier(), parameters, scoring = scorer)\n",
    "\n",
    "gscv.fit(x_df_extended.values, y_df.values)\n",
    "best_model = gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_model = gscv.best_estimator_\n",
    "\n",
    "#best_model = KNeighborsClassifier(n_neighbors=5)\n",
    "#best_model.fit(x_df_extended.values, y_df.values)\n",
    "\n",
    "kf = KFold(n_splits = 3)\n",
    "adf = pd.DataFrame({}, columns = ['accuracy_all', 'accuracy_healthy', 'accuracy_epilepsy'])\n",
    "index = 0\n",
    "\n",
    "for train_index, test_index in kf.split(x_df_extended.values):\n",
    "    x_train = x_df_extended.values[train_index, :]\n",
    "    x_test = x_df_extended.values[test_index, :]\n",
    "    y_train = y_df.values[train_index]\n",
    "    y_test = y_df.values[test_index]\n",
    "    \n",
    "    best_model.fit(x_train, y_train)\n",
    "    \n",
    "    #y_predict = best_model.predict(x_test)\n",
    "    y_predict = best_model.predict_proba(x_test)[:, 0]\n",
    "    mask = y_predict > (1-1e-7)\n",
    "    y_predict[mask] = 0\n",
    "    y_predict[~mask] = 1\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_predict)\n",
    "    accuracy_all = best_model.score(x_test, y_test)\n",
    "    accuracy_epilepsy = float(cm[1,1])/float(cm[1,0]+cm[1,1])\n",
    "    accuracy_healthy = float(cm[0,0])/float(cm[0,0]+cm[0,1])\n",
    "    \n",
    "    adf.loc[index] = [accuracy_all, accuracy_healthy, accuracy_epilepsy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter: {'penalty': 'l2', 'class_weight': {1: 10}}\n",
      "Best precision score: 0.656070830768\n",
      "accuracy_all         0.996495\n",
      "accuracy_healthy     0.680844\n",
      "accuracy_epilepsy    0.636364\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print 'Best parameter:', gscv.best_params_\n",
    "print 'Best precision score:', gscv.best_score_\n",
    "print adf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most positive variables\n",
      "0.631456802507 component_521\n",
      "0.613221746243 component_1687\n",
      "0.569949174282 component_1564\n",
      "0.558037376196 component_1306\n",
      "0.546967577738 component_772\n",
      "0.511798694177 component_1432\n",
      "0.498109631231 component_614\n",
      "0.4964266729 component_1035\n",
      "0.485448484834 component_2195\n",
      "0.478058061246 component_560\n",
      "0.475250637027 component_791\n",
      "0.472532784435 component_2211\n",
      "0.454732491616 component_1371\n",
      "0.452287415823 component_937\n",
      "0.430125809879 component_1409\n",
      "0.418194332058 component_1768\n",
      "0.402829655689 component_256\n",
      "0.400978847363 component_1993\n",
      "0.39655782096 component_1054\n",
      "0.392818782863 component_1024\n",
      "0.387464855475 component_1832\n"
     ]
    }
   ],
   "source": [
    "# get coefficient\n",
    "best_model = gscv.best_estimator_\n",
    "coef = best_model.coef_.flatten()\n",
    "\n",
    "most_pos_var_index = np.argsort(coef)[-21:][::-1]\n",
    "most_neg_var_index = np.argsort(coef)[0:3]\n",
    "\n",
    "print 'most positive variables'\n",
    "for index in most_pos_var_index:\n",
    "    print coef[index], x_df_extended.columns[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
