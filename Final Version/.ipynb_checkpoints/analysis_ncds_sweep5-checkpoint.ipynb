{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn import linear_model\n",
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The file explain is a rtf file explaining which variables are numeric and which are categorical. There are 1765 variables, the first being ID and it's part in the explain file does not contain the target string 'the SPSS measurement level is'. The others' part contains either NOMINAL, ORDINAL or SCALE. Only SCALE is numeric.\n",
    "\n",
    "column 'n503930' is epilepsy status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# file path of explain file\n",
    "explain_path = '/Users/hung-yiwu/Documents/AC209a_project/data/ncds_sweep5/mrdoc/allissue/ncds5cmi_ukda_data_dictionary.rtf'\n",
    "\n",
    "# open explain file\n",
    "explain = open(explain_path, 'r')\n",
    "\n",
    "# read the whole file as a single giant string\n",
    "explain_text = explain.read()\n",
    "\n",
    "# target string\n",
    "target_string = 'the SPSS measurement level is'\n",
    "\n",
    "# locate target string in the whole file\n",
    "target_loc = [m.start() for m in re.finditer(target_string, explain_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ncdsid serial number', 'PERSON NUMBER', 'Sex of Cohort Member', 'Standard region at NCDS5', 'NCDS5 Government Office Region', 'Responded to Cohort Member Interview', 'Responded to What Do You Think Questionnaire', 'Responded to Your Life Since 1974 Questionnaire', 'Time of Interview (mins)', 'CMI:2,A1a) Current main economic activity']\n"
     ]
    }
   ],
   "source": [
    "target_string_2 = 'Variable label ='\n",
    "target_loc_2 = [m.end() for m in re.finditer(target_string_2, explain_text)]\n",
    "\n",
    "var_name_list = []\n",
    "\n",
    "for loc in target_loc_2:\n",
    "    start_point = loc+8\n",
    "    end_point = explain_text.find('\\par', loc)\n",
    "    var_name_list.append(explain_text[start_point:end_point])\n",
    "\n",
    "print var_name_list[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hung-yiwu/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (4,8,9,79,128,129,130,131,132,133,134,136,139,142,145,148,151,154,157,160,163,166,171,172,173,174,177,178,179,180,183,184,186,187,188,189,190,191,192,193,194,196,197,199,200,201,202,203,204,205,206,207,209,212,215,229,231,234,235,236,237,240,241,242,243,249,257,286,289,290,291,292,295,296,297,298,301,302,303,304,407,416,425,444,445,449,450,453,454,455,459,460,463,464,465,469,470,473,474,475,479,480,483,484,489,490,495,496,501,502,541,542,546,547,551,552,556,557,560,561,572,573,574,575,576,578,579,580,581,582,584,585,586,587,588,590,591,592,593,594,619,621,623,625,627,629,631,633,635,637,639,641,643,645,648,650,653,655,658,660,664,665,669,673,674,678,682,683,687,691,692,696,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,760,766,806,808,810,812,825,827,830,831,832,833,834,835,836,837,838,839,840,841,842,846,848,849,850,851,852,855,860,878,879,915,928,929,933,934,938,940,942,943,945,946,953,954,955,958,959,960,964,965,966,967,969,971,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1053,1088,1124,1127,1130,1133,1135,1136,1139,1142,1145,1148,1160,1163,1166,1177,1180,1184,1190,1193,1203,1204,1206,1240,1257,1283,1296,1299,1300,1301,1302,1303,1304,1307,1308,1309,1310,1311,1312,1313,1314,1318,1320,1325,1328,1329,1330,1331,1332,1333,1335,1337,1339,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1362,1364,1365,1368,1370,1383,1394,1400,1402,1412,1422,1432,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1474,1484,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1512,1513,1517,1518,1521,1522,1523,1527,1528,1531,1532,1533,1537,1538,1541,1542,1543,1547,1548,1551,1552,1557,1558,1563,1564,1569,1570,1598,1609,1610,1614,1615,1619,1620,1624,1625,1628,1629,1630,1631,1632,1634,1635,1636,1637,1638,1640,1641,1642,1643,1644,1646,1647,1648,1649,1650,1654,1679,1685,1691,1697,1699,1704,1709,1714,1725,1734,1743,1752,3168,3170,3171,3172,3175,3176,3177,3178,3179,3180,3181,3182,3188) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# file path of data file\n",
    "data_path = './ncds_sweep5/tab/ncds5cmi.tab'\n",
    "\n",
    "# read data file into Pandas DataFrame\n",
    "# delimiter is tab\n",
    "# use column 'ncdsid' as index\n",
    "data = pd.read_csv(data_path, delimiter='\\t').set_index('ncdsid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2745 categorical predictor variables\n",
      "442 numerical predictor variables\n",
      "3187 total predictor variables\n",
      "79478 predictor variables after dummy expansion\n",
      "11469 observations\n"
     ]
    }
   ],
   "source": [
    "# identify categorical variables by target strings in explain file\n",
    "cat_col = []\n",
    "\n",
    "for index, loc in enumerate(target_loc):\n",
    "    # get feature character\n",
    "    char = explain_text[loc+len(target_string)+10]\n",
    "    \n",
    "    if data.columns[index] == 'n503930':\n",
    "        # response variable\n",
    "        continue\n",
    "    elif char == 'O' or char == 'o' or char == 'N' or char == 'n'\\\n",
    "        or 'region' in data.columns[index]:\n",
    "        # it is SPSS data type ORDINAL or NOMINAL\n",
    "        # it is categorical data\n",
    "        cat_col.append(index)\n",
    "\n",
    "print len(cat_col), 'categorical predictor variables'\n",
    "print len(data.columns)-1-len(cat_col), 'numerical predictor variables'\n",
    "print len(data.columns)-1, 'total predictor variables'\n",
    "\n",
    "# calculate number of variables after dummy expansion\n",
    "col_len = np.zeros(data.shape[1])\n",
    "\n",
    "for index, col in enumerate( data.columns ):\n",
    "    if index in cat_col:\n",
    "        # categorical variable\n",
    "        # require expansion\n",
    "        col_len[index] = len( data[col].unique() )\n",
    "    else:\n",
    "        # numerical variable\n",
    "        # does not require expansion\n",
    "        col_len[index] = 1\n",
    "\n",
    "print int( sum(col_len) )-1, 'predictor variables after dummy expansion'\n",
    "print data.shape[0], 'observations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value error\n",
      "value error\n",
      "value error\n",
      "value error\n",
      "value error\n",
      "value error\n",
      "value error\n",
      "value error\n",
      "value error\n",
      "value error\n",
      "value error\n",
      "value error\n",
      "value error\n",
      "value error\n",
      "value error\n",
      "value error\n",
      "value error\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 79462 elements, new values have 79479 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d6c00397a6f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mdata_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0msub_df_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mdata_expanded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/hung-yiwu/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   2683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2685\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2686\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/properties.pyx\u001b[0m in \u001b[0;36mpandas.lib.AxisProperty.__set__ (pandas/lib.c:44748)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/hung-yiwu/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/hung-yiwu/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m   2633\u001b[0m             raise ValueError('Length mismatch: Expected axis has %d elements, '\n\u001b[1;32m   2634\u001b[0m                              \u001b[0;34m'new values have %d elements'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2635\u001b[0;31m                              (old_len, new_len))\n\u001b[0m\u001b[1;32m   2636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2637\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 79462 elements, new values have 79479 elements"
     ]
    }
   ],
   "source": [
    "new_columns = []\n",
    "sub_df_list = []\n",
    "\n",
    "for index, col in enumerate(data.columns):\n",
    "    if index in cat_col:\n",
    "        # categorical variable\n",
    "        # dummify\n",
    "        dummies = pd.get_dummies(data[col])\n",
    "        # append value\n",
    "        sub_df_list.append( dummies )\n",
    "        # append column name\n",
    "        new_columns.extend([str(col)+'='+str(value) for value in data[col].unique()])\n",
    "    else:\n",
    "        # numeric variable\n",
    "        # append value\n",
    "        try:\n",
    "            sub_df_list.append( data[col].apply(lambda x: 0 if x == ' ' else float(x)) )\n",
    "        except ValueError:\n",
    "            print 'value error'\n",
    "        # append column name\n",
    "        new_columns.append(col)\n",
    "        \n",
    "data_expanded = pd.concat( sub_df_list, axis=1 )\n",
    "data_expanded.columns = new_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pos. = 772\tVariable = n5765\tVariable label = 4I Fits,convulsions-ever called epileptic\n",
    "\n",
    "This variable is  numeric, the SPSS measurement level is ordinal.\n",
    "\n",
    "\tValue label information for n5765\n",
    "\tValue = 1\tLabel = YES\n",
    "\tValue = 2\tLabel = NO\n",
    "\tValue = 8\tLabel = DONT   KNOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# separate predictor and response variables\n",
    "y = data_expanded['n503930'].values\n",
    "x = data_expanded.drop('n503930', axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# binary question: epilepsy or not\n",
    "y_t = np.array( [1 if value == 1 else 0 for value in y] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reduce dimension by pca\n",
    "# already did a full decomposition and decided to use first 4 principal components\n",
    "# decomposition takes time so did not do it twice to show everything\n",
    "pca_model = decomposition.PCA( n_components = 4)\n",
    "x_t = pca_model.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize principal components contribution\n",
    "plt.plot(np.cumsum(pca_model.explained_variance_ratio_))\n",
    "plt.xlabel('number of principal components used')\n",
    "plt.ylabel('cumulative explained variance ratio')\n",
    "plt.title('first 4 principal components should suffice')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# classify seizure status by multi-class logistic regression with CV\n",
    "model = linear_model.LogisticRegressionCV()\n",
    "model.fit(x_t, y_t)\n",
    "rsq = model.score(x_t, y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coef = model.coef_\n",
    "pc = pca_model.components_\n",
    "importance = np.sum( coef.reshape(4,-1)*pc, axis = 0 )\n",
    "plt.plot( importance )\n",
    "plt.xlabel('predictor variables')\n",
    "plt.ylabel('coefficient')\n",
    "plt.title('some predictors are more important than others')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get variable list\n",
    "var_list = data_expanded.drop('n503930', axis=1).columns\n",
    "\n",
    "# get top three positive coef\n",
    "top_pos_ind = np.argsort(importance)[-5:][:-1]\n",
    "top_pos = list( var_list[top_pos_ind] )\n",
    "print 'top positive variables'\n",
    "print top_pos\n",
    "print ''\n",
    "\n",
    "# get top three negative coef\n",
    "top_neg_ind = np.argsort(importance)[0:2]\n",
    "top_neg = list( var_list[top_neg_ind] )\n",
    "print 'top negative variables'\n",
    "print top_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
